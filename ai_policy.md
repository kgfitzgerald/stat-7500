---
layout: page
title: AI / LLM policy
description: >-
    Software intro
nav_exclude: true
nav_order: 4
---

 
# AI /LLM policy (i.e. usage of ChatGPT, etc.)[^1] 
 
#### TLDR: you’re responsible for understanding how to solve problems, cite any use of AI
 
In general, we treat AI-based assistance, such as ChatGPT, the same way we treat collaboration with other people; you are welcome to talk about your ideas with other people, both inside and outside the classroom, as well as with AI-based assistants. 
 
However, **all work you submit must be primarily your own, and may not be completed, in whole or in substantial part, by other humans or chatbots, AI, etc. You also must properly acknowledge (cite) any ideas / code / solutions that did not originate from you.** In all cases, you are responsible for understanding all work that is turned in and may be periodically asked to orally explain your answers. 
 
I expect you *will* use AI / LLMs periodically to assist you in this course. Responsible use of AI is not “against the rules,” and you should not feel the need to hide it. If/when you use AI while working on an assignment, you are expected to provide the following with your submission:  
1. A statement acknowledging your use of AI and which tool you used 
2. A precise description of the prompt(s) you used on which problem(s) 
3. A brief reflection of your takeaway / analysis of the output provided by the tool, including your level of confidence in it. A couple of sentences will suffice. 
 
## Considerations for responsible AI / LLM usage 

AI / LLMs are likely to be used in your future workplace and can be an effective tool for the modern statistician / data scientist. However, there are both effective and detrimental ways that LLMs can be used in a learning context. Here are a few things to consider when choosing whether/how to use AI in your coursework: 

+ AI / LLMs can hallucinate and provide incorrect answers. You must develop your own foundational knowledge of a subject in order to effectively judge and verify whether an LLM’s output is trustworthy.  
+ AI / LLMs use an enormous amount of energy. In order to be climate-conscious, we need discerning use of AI and should be careful not to over-rely on it when other methods (e.g. Google search, non-AI computational tools, human effort) will suffice.  
+ Employers are interested in people who can, among other things, achieve Task X (with or without LLMs) correctly and efficiently and who can effectively document and communicate how they achieved Task X so that it can be verified and reproduced by someone else. This motivates the policy described above.  
+ One of the broader / more existential threats posed by AI is its potential to diminish human connection. Be mindful of how often you are turning to AI for help when you otherwise would be turning to a human. There is value in day-to-day interactions with classmates, tutors, and professors that go beyond efficiently completing an assignment.  
 
## Tips for when AI assistance can be especially *useful* and *appropriate* 

+ Debugging code or interpreting error messages 
+ Clarifying course concepts. For example: 
    + “provide me with an intuitive explanation of XYZ” 
    + “help me understand why ABC happens in this context” 
    + “I’m confused about the difference between ABC and XYZ”  
+ Deepening understanding of posted solutions 
+ Generating additional practice questions and step-by-step explanations when studying 
 
## (Non-exhaustive) scenarios when AI assistance would be *inappropriate* 

+ Copying / typing a homework problem into ChatGPT and having it generate a full solution from start to finish. Homework is intended to build your general problem solving intuition, and you are responsible for coming up with the steps to solve the problem.  
+ Copying output from ChatGPT directly into your submission. Just as you should not let a classmate write content directly into your submission, so also should you avoid using AI assistance in such a way that directly adds content to your submission. 
+ Using AI on an open-ended problem or writing assignment that asks for your reflection, opinion, or meta-cognitive thought-processes. It is considered academic irresponsibility to use AI to generate an answer that does not reflect what you truly think and believe. I am interested in what you think, not what an LLM thinks.  
+ Submitting an assignment that has ideas, code, or solutions that originated from AI but is not properly cited. This is plagiarism and a violation of academic integrity.  
 
_**If at any point you are unsure whether a particular use-case of AI is appropriate, please ask!**_

[^1]: This policy has been adapted from language provided by Drs. Keegan Kang (Bucknell), Yimin Zhang, Michael Posner, and Villanova University